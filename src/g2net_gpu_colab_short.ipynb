{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQMzadIy799t"
   },
   "source": [
    "\n",
    "# G2Net Playground GPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvF9QKLm_cEJ"
   },
   "source": [
    "This notebook has been created to serve as a guided tour to training G2Net models by using Colab GPU. It **MAKES USE** of the code in the project-like tree uploaded to my GitHub as well, a code that rocketed the team (ROC & Roll) to top 8% and a bronze medal in its first competition. With all that said, let's ROC it! (Hope you get the joke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6VkgQFwBIsw"
   },
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcftmfyrhFo9"
   },
   "source": [
    "### 1.1 Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "507TSYzKhF_c"
   },
   "source": [
    "Not only a network of Gravitational Waves, Geophysics and Machine Learning experts, G2Net was also released as a Kaggle competition. I'm pretty sure that you have heard about the discovery of Gravitational Waves (GW), signals from colliding binary black holes, back in 2015. If not, you can refresh your memory with [The Sound of Two Black Holes Colliding](https://www.youtube.com/watch?v=QyDcTbR-kEA). \n",
    "\n",
    "The aim of this competition is to detect GW signals from the mergers of binary black holes. Specifically, the participant was expected to build a model to analyse synthetic GW time-series data from a network of Earth-based detectors (LIGO Hanford, LIGO Livingston and Virgo). The [Data](https://www.kaggle.com/c/g2net-gravitational-wave-detection/data) was simulated with a sampling rate of 2048 Hz. Each of the time-series originated by the corresponding detector comprises a channel (three in total).\n",
    "\n",
    "In the context of this notebook, data has been already standardised (with training set mean and standard deviation), transposed (to ease channels last format) and saved to TensorFlow Records format. Such data can be found in my Kaggle profile, [Training Dataset](https://www.kaggle.com/salbeal94/g2net-float32-train) and [Test Dataset](https://www.kaggle.com/salbeal94/g2net-float32-test). Since it is a classification task, the output is the black hole merger occurence probability. As per the evaluation/validation metric, it is the AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZzaCoZThMfh"
   },
   "source": [
    "### 1.2 Implemented Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkfwBa3S-FgA"
   },
   "source": [
    "After many iterations, the model used for the competition ended up being a 2D Convolutional Neural Network (CNN) preceded by a series of time-series processing techniques. Even the preprocessing has been here implemented as part of the model to stay loyal to the end-to-end philosophy. Such a model contains a series of building blocks several of them presented as trainable Tensorflow Keras layers. These are described as follows:\n",
    "- **Tukey Window (trainable/non-trainable)**: Introduces a tappering effect that forces the signal amplitude to decay until having zero values at the ends. It is applied to avoid artefacts stemming from discontinuities when taking Fourier transforms or similar.\n",
    "\n",
    "- **Bandpass Filter (trainable/non-trainable)**: Applies a filter with the frequency response of a Butterworth filter. The idea is to filter out or attenuate frequencies that have nothing to do with the merger.\n",
    "\n",
    "- **Constant-Q Transform (trainable/non-trainable)**: Transforms the time-domain signal into the time-frequency domain. In other words, it converts a time-domain signal to a spectrogram. Particularly, the PyTorch CQT1992v2 implementation from [nnAudio](https://github.com/KinWaiCheuk/nnAudio) has been taken as reference. It has been re-implemented in TensorFlow for being one of the most cost-effective solutions offered by the library. As an additional functionality, the layer keeps track of maximum spectrogram magnitudes and normalises its values to a preset range for the sake of stability. The output spectrogram is later resized with bilinear interpolation to adapt it to the downstream CNN recommended input sizes.\n",
    "\n",
    "- **Channel Permutation (non-trainable)**: Randomly decides whether to apply a stochastic permutation of the channels. The aim is to make the prediction a bit less independent of the detector it comes from, pressumably acting as a regularisation layer.\n",
    "\n",
    "- **Spectral Masking (non-trainable)**: Randomly decides whether to stochastically mask certain time or frequency bands. Similar to the permutation, the idea is for this layer to act as a regularising operation.\n",
    "\n",
    "- **Convolutional Neural Network (trainable/non-trainable)**: Used as backbone to extract the relevant features to be ingested by a single fully-connected neuron with sigmoid activation (after flattening). Given its performance-complexity trade-off in the ImageNet dataset, the EfficientNet family from [AutoML](https://github.com/google/automl) was selected as a more than appropriate model for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SsrWhul9ASn"
   },
   "source": [
    "![G2Net Model](https://github.com/salvaba94/G2Net/blob/main/img/Model.png?raw=true \"G2Net Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8B4eskr10Cg"
   },
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BB-pV4-c95z9"
   },
   "source": [
    "### 2.1 Environment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-lnhaAD6Wo0"
   },
   "source": [
    "Before starting with implementation-specific details, let's configure some aspects of the environment: \n",
    "\n",
    "- Make sure the Colab environment type is set to GPU going to ```Runtime → Change runtime type → GPU``` and check its characteristics.\n",
    "- Mount your Google Drive to save any output model after the execution.\n",
    "- Install any library that might be missing from the defaults.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23TOba33L4qf",
    "outputId": "fbed51b3-a44d-4a6e-e69d-93c622ec0b89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 20 18:15:46 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.02    Driver Version: 526.98       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:0A:00.0  On |                  Off |\n",
      "|  0%   23C    P8    19W / 508W |   1631MiB / 24564MiB |     13%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A        27      G   /Xwayland                       N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = \"\\n\".join(gpu_info)\n",
    "if gpu_info.find(\"failed\") >= 0:\n",
    "  print(\"GPU execution environment is not activated.\")\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0i6EHThj5Oal",
    "outputId": "e10cf83a-7123-4dfa-d8f9-3e63601c3f8a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/gdrive\", force_remount = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lia9PRy4RtNd",
    "outputId": "9bf2a67b-6ced-4b65-a09a-f0f3989c68d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: pip: not found\r\n",
      "/bin/sh: 1: pip: not found\r\n",
      "fatal: destination path 'g2net/src/automl' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow-addons\n",
    "# !pip install adabelief-tf\n",
    "# !git clone https://github.com/salvaba94/G2Net.git g2net\n",
    "# !git clone https://github.com/google/automl.git g2net/src/automl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjfq4VuL_5-3"
   },
   "source": [
    "### 2.2 Code Configuration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvBtCNP4AOd4"
   },
   "source": [
    "\n",
    "Now it is high time to start with the Python specifics. Run the following cell to import the necessary libraries for the code to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q-DAIsqcRtNj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 18:15:46.861633: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-20 18:15:47.496749: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-20 18:15:47.496835: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-20 18:15:47.496843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "# from tensorflow import AUTOTUNE\n",
    "from tensorflow.python.client import device_lib\n",
    "# from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "# from tensorflow.keras.layers.preprocessing import Resizing\n",
    "from adabelief_tf import AdaBeliefOptimizer\n",
    "from datetime import datetime\n",
    "from pathlib import Path, os\n",
    "from functools import partial\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "from typing import Tuple, Union, Mapping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDgrlDxGCgCW"
   },
   "source": [
    "Set the configuration variables necessary for the code to run. Here is where you should come if you would like to play with the model. Don't worry if some of the variables are not clear enough at this point. Their utility can be derived as these are used all along the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2NS3QU9s8I3A"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "### General data #############################################################\n",
    "    N_SAMPLES, N_DETECT = 4096, 3\n",
    "\n",
    "### Training #################################################################\n",
    "    FROM_TFR = False\n",
    "    MODEL_TRAIN = True\n",
    "    MODEL_SAVE_NAME = \"Model_Ref.h5\"\n",
    "    MODEL_PRELOAD = False\n",
    "    MODEL_PRELOAD_NAME = \"Model_Ref.h5\"\n",
    "    HISTORY_NAME = \"history_train.csv\"\n",
    "\n",
    "    MODEL_PATH = Path(\"models\")\n",
    "    CKPT_PATH = Path(\"checkpoints\")\n",
    "\n",
    "    SPLIT = 0.98\n",
    "    SEED_SPLIT = 21\n",
    "    BATCH_SIZE = 64\n",
    "    BATCH_SIZE_TEST = 32\n",
    "    EPOCHS = 1\n",
    "    LEARNING_RATE = 0.0001\n",
    "    \n",
    "### Prediction ################################################################\n",
    "    MODEL_PREDICT = True\n",
    "    PREDICTIONS_NAME = \"submission.csv\"\n",
    "\n",
    "\n",
    "### Model ####################################################################\n",
    "    TUKEY_SHAPE = 0.25\n",
    "    TRAINABLE_TUKEY = False\n",
    "\n",
    "    DEGREE_FILT = 6\n",
    "    F_BAND_FILT = (20., 500.)\n",
    "    TRAINABLE_FILT = True\n",
    "\n",
    "    SAMPLE_RATE = 2048\n",
    "    F_BAND_SPEC = (20., 500.)\n",
    "    HOP_LENGTH = 64\n",
    "    BINS_PER_OCTAVE = 12\n",
    "    WINDOW_CQT = \"hann\"\n",
    "    TRAINABLE_CQT = False\n",
    "    \n",
    "    IMAGE_SIZE = 120\n",
    "\n",
    "    P_PERM = 0.1\n",
    "\n",
    "    P_MASK = 0.15\n",
    "    N_MAX_MASK = 2\n",
    "    W_MASK = (IMAGE_SIZE // 64, IMAGE_SIZE // 6)\n",
    "    \n",
    "    MODEL_ID = \"efficientnetv2-b0\"\n",
    "    MODEL_ID_WEIGHTS = \"imagenet\"\n",
    "\n",
    "### Plotting #################################################################\n",
    "    PLOT_EXAMPLE = True\n",
    "    PLOT_TEST = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfL17IFSIvdX"
   },
   "source": [
    "When making use of Colab GPUs, data ingested by the model should be stored locally. Taking into consideration the great size of the datasets, data can be affordably downloaded in several ways:\n",
    " * Firstly, one can use [Kaggle API](https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb#scrollTo=OppyMnCuWjzJ).\n",
    " * Secondly, you can simply upload the data to your Google Drive (assuming you have enough space) and manually copy it from the folder is has been mounted into. \n",
    " * Thirdly, one can use Google Cloud Storage (GCS) buckets. Fortunately, Kaggle is so integrated with Google that public datasets get uploaded to Google Cloud. \n",
    " \n",
    "We'll use the third method due to its speed when it comes to downloading files. To know the public GCS bucket addresses one should just run the following in a Kaggle notebook:\n",
    "```\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "MODEL_BUCK = KaggleDatasets().get_gcs_path(\"automl-efficientnetv2-ckpt\")\n",
    "TEST_PATH = KaggleDatasets().get_gcs_path(\"g2net-float32-test\")\n",
    "TRAIN_PATH = KaggleDatasets().get_gcs_path(\"g2net-float32-train\")\n",
    "```\n",
    "\n",
    "The output addresses should be pasted below as raw strings (check them from time to time as they are periodically changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ci1FwjxuRtNo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OV_PATH:        /mnt/c/Users/Chris/OneDrive\\ -\\ Georgia\\ Institute\\ of\\ Technology/GaTech/CS7643/Deep\\ Learning\\Group Project/G2Net\n",
      "SRC_PATH:       /mnt/c/Users/Chris/OneDrive\\ -\\ Georgia\\ Institute\\ of\\ Technology/GaTech/CS7643/Deep\\ Learning\\Group Project/G2Net/src\n",
      "CKT_PATH:       /mnt/c/Users/Chris/OneDrive\\ -\\ Georgia\\ Institute\\ of\\ Technology/GaTech/CS7643/Deep\\ Learning\\Group Project/G2Net/tfrecords/effnet/imagenet\n",
      "TRAIN_PATH:     /mnt/c/Users/Chris/OneDrive\\ -\\ Georgia\\ Institute\\ of\\ Technology/GaTech/CS7643/Deep\\ Learning\\Group Project/G2Net/tfrecords/train/train\n",
      "TEST_PATH:      /mnt/c/Users/Chris/OneDrive\\ -\\ Georgia\\ Institute\\ of\\ Technology/GaTech/CS7643/Deep\\ Learning\\Group Project/G2Net/tfrecords/test/test\n",
      "AUTOML_PATH:    /mnt/c/Users/Chris/OneDrive\\ -\\ Georgia\\ Institute\\ of\\ Technology/GaTech/CS7643/Deep\\ Learning\\Group Project/G2Net/src/automl\n",
      "EFFNETV2_PATH:  /mnt/c/Users/Chris/OneDrive\\ -\\ Georgia\\ Institute\\ of\\ Technology/GaTech/CS7643/Deep\\ Learning\\Group Project/G2Net/src/automl/efficientnetv2\n"
     ]
    }
   ],
   "source": [
    "project_directory = r'/mnt/c/Users/Chris/OneDrive\\ -\\ Georgia\\ Institute\\ of\\ Technology/GaTech/CS7643/Deep\\ Learning\\Group Project/G2Net'\n",
    "os.environ[\"MODEL_BUCK\"] = project_directory + r'/tfrecords/effnet'\n",
    "os.environ[\"TEST_BUCK\"] = project_directory + r'/tfrecords/test'\n",
    "os.environ[\"TRAIN_BUCK\"] = project_directory + r'/tfrecords/train'\n",
    "MODEL_BUCK = os.environ[\"MODEL_BUCK\"]\n",
    "TEST_BUCK = os.environ[\"TEST_BUCK\"]\n",
    "TRAIN_BUCK = os.environ[\"TRAIN_BUCK\"]\n",
    "\n",
    "OV_PATH = Path(project_directory)\n",
    "SRC_PATH = str(Path(OV_PATH, \"src\"))  # SRC_PATH = str(Path(OV_PATH, \"g2net\", \"src\"))\n",
    "\n",
    "CKT_PATH = MODEL_BUCK + \"/\" + Config.MODEL_ID_WEIGHTS\n",
    "TRAIN_PATH = TRAIN_BUCK + \"/train\"\n",
    "TEST_PATH = TEST_BUCK + \"/test\"\n",
    "\n",
    "AUTOML_PATH = str(Path(SRC_PATH, \"automl\"))\n",
    "EFFNETV2_PATH = str(Path(AUTOML_PATH, \"efficientnetv2\"))\n",
    "\n",
    "print('OV_PATH:       ', OV_PATH)\n",
    "print('SRC_PATH:      ', SRC_PATH)\n",
    "print('CKT_PATH:      ', CKT_PATH)\n",
    "print('TRAIN_PATH:    ', TRAIN_PATH)\n",
    "print('TEST_PATH:     ', TEST_PATH)\n",
    "print('AUTOML_PATH:   ', AUTOML_PATH)\n",
    "print('EFFNETV2_PATH: ', EFFNETV2_PATH)\n",
    "\n",
    "# if SRC_PATH not in sys.path:\n",
    "#     sys.path.append(SRC_PATH)\n",
    "#     sys.path.append(AUTOML_PATH)\n",
    "#     sys.path.append(EFFNETV2_PATH)\n",
    "#\n",
    "# from utilities import PlottingUtilities, GeneralUtilities\n",
    "# from ingest import TFRDatasetCreator, NPYDatasetCreator, DatasetGeneratorTF\n",
    "# from models import G2NetEfficientNet\n",
    "# from train import RocLoss, Acceleration, CosineAnnealingRestarts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQ3m8_mFNgGY"
   },
   "source": [
    "Run the next cell to tune the paths and add G2Net source code and AutoML EfficientNet model paths to Python path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Qh3Yz_vwRtNx"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libffi.so.7: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 15>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     12\u001B[0m     sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mappend(AUTOML_PATH)\n\u001B[1;32m     13\u001B[0m     sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mappend(EFFNETV2_PATH)\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutilities\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PlottingUtilities, GeneralUtilities\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mingest\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TFRDatasetCreator, NPYDatasetCreator, DatasetGeneratorTF\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m G2NetEfficientNet\n",
      "File \u001B[0;32m/mnt/c/Users/Chris/OneDrive - Georgia Institute of Technology/GaTech/CS7643 Deep Learning/Group Project/G2Net/src/utilities/__init__.py:9\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mCreated on Tue Jul 27 21:45:24 2021\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m@author: salva\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mGeneralUtilities\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GeneralUtilities\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mPlottingUtilities\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PlottingUtilities\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03mDefine what is going to be imported as public with \"from utilities import *\"\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     14\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlottingUtilities\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGeneralUtilities\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/mnt/c/Users/Chris/OneDrive - Georgia Institute of Technology/GaTech/CS7643 Deep Learning/Group Project/G2Net/src/utilities/PlottingUtilities.py:8\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# -*- coding: utf-8 -*-\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mCreated on Tue Jul 27 21:54:07 2021\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m@author: salva\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlibrosa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/librosa/__init__.py:209\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;66;03m# And all the librosa sub-modules\u001B[39;00m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_cache\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cache\n\u001B[0;32m--> 209\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m core\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m beat\n\u001B[1;32m    211\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m decompose\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/librosa/core/__init__.py:6\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\" Core IO and DSP functions\"\"\"\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconvert\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# pylint: disable=wildcard-import\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# pylint: disable=wildcard-import\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspectrum\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# pylint: disable=wildcard-import\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpitch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# pylint: disable=wildcard-import\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/librosa/core/audio.py:8\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpathlib\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msoundfile\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msf\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01maudioread\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/soundfile.py:17\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SEEK_SET, SEEK_CUR, SEEK_END\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mctypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m find_library \u001B[38;5;28;01mas\u001B[39;00m _find_library\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m_soundfile\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ffi \u001B[38;5;28;01mas\u001B[39;00m _ffi\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     20\u001B[0m     _unicode \u001B[38;5;241m=\u001B[39m unicode  \u001B[38;5;66;03m# doesn't exist in Python 3.x\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/_soundfile.py:2\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# auto-generated file\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01m_cffi_backend\u001B[39;00m\n\u001B[1;32m      4\u001B[0m ffi \u001B[38;5;241m=\u001B[39m _cffi_backend\u001B[38;5;241m.\u001B[39mFFI(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_soundfile\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      5\u001B[0m     _version \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0x2601\u001B[39m,\n\u001B[1;32m      6\u001B[0m     _types \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x68\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x67\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x75\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x6A\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x69\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x02\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x67\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x02\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x02\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x6A\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x1C\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x02\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x02\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x04\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x36\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x6B\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x17\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x36\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x6F\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x17\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x36\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x02\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x17\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x36\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x17\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x36\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x74\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x17\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x36\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x04\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x17\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x36\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x17\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x07\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x04\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x36\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x04\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x36\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x04\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x17\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x04\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x36\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x75\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x17\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x04\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x75\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0F\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x09\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x09\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x02\u001B[39;00m\u001B[38;5;130;01m\\x09\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x09\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x02\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0E\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0B\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x0B\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x02\u001B[39;00m\u001B[38;5;130;01m\\x0B\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x0D\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x51\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x56\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x59\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x5E\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x05\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m     _typenames \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x66\u001B[39;00m\u001B[38;5;124mSF_FORMAT_INFO\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x67\u001B[39;00m\u001B[38;5;124mSF_INFO\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x68\u001B[39;00m\u001B[38;5;124mSF_VIRTUAL_IO\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x69\u001B[39;00m\u001B[38;5;124mSNDFILE\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x36\u001B[39;00m\u001B[38;5;124msf_count_t\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x71\u001B[39;00m\u001B[38;5;124msf_vio_get_filelen\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x72\u001B[39;00m\u001B[38;5;124msf_vio_read\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x70\u001B[39;00m\u001B[38;5;124msf_vio_seek\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x71\u001B[39;00m\u001B[38;5;124msf_vio_tell\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x00\u001B[39;00m\u001B[38;5;130;01m\\x73\u001B[39;00m\u001B[38;5;124msf_vio_write\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m     11\u001B[0m )\n",
      "\u001B[0;31mImportError\u001B[0m: libffi.so.7: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "OV_PATH = Path(\"/content\")\n",
    "SRC_PATH = str(Path(OV_PATH, \"g2net\", \"src\"))\n",
    "CKT_PATH = MODEL_BUCK + \"/\" + Config.MODEL_ID_WEIGHTS\n",
    "TRAIN_PATH = TRAIN_BUCK + \"/train\"\n",
    "TEST_PATH = TEST_BUCK + \"/test\"\n",
    "\n",
    "AUTOML_PATH = str(Path(SRC_PATH, \"automl\"))\n",
    "EFFNETV2_PATH = str(Path(AUTOML_PATH, \"efficientnetv2\"))\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)\n",
    "    sys.path.append(AUTOML_PATH)\n",
    "    sys.path.append(EFFNETV2_PATH)\n",
    "    \n",
    "from utilities import PlottingUtilities, GeneralUtilities\n",
    "from ingest import TFRDatasetCreator, NPYDatasetCreator, DatasetGeneratorTF\n",
    "from models import G2NetEfficientNet\n",
    "from train import RocLoss, Acceleration, CosineAnnealingRestarts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vIVWrJQDWA9"
   },
   "source": [
    "The following cell automatically configures the TensorFlow strategy and device (not really relevant for GPU) and sets the data type to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HvpAB7BRtNm",
    "outputId": "2648b7d2-2e40-49a1-f975-010ce33f2245"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Acceleration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Create strategy and define data types for data and tensorflow models\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m strategy, device \u001B[38;5;241m=\u001B[39m \u001B[43mAcceleration\u001B[49m\u001B[38;5;241m.\u001B[39mget_acceleration()\n\u001B[1;32m      3\u001B[0m dtype \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mfloat32\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Acceleration' is not defined"
     ]
    }
   ],
   "source": [
    "# Create strategy and define data types for data and tensorflow models\n",
    "strategy, device = Acceleration.get_acceleration()\n",
    "dtype = tf.float32 # Do not modify since TF Records are in tf.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4NEqmyYKK8W"
   },
   "source": [
    "Since each TF Record contains several examples (each with ID, time-domain signals and label if any), one might lose track of the number of examples in training and test sets. Actually, it needs to be known to figure out the number of steps per epoch. Such information is contained in two CSV that need to be locally stored. This is the purpose of the following lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r1rNKp8dV_xB",
    "outputId": "1d5db502-ffb5-46a3-a752-d93ba9eee20b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: gsutil: not found\r\n",
      "/bin/sh: 1: gsutil: not found\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p g2net-float32-train\n",
    "!mkdir -p g2net-float32-test\n",
    "!gsutil -m cp -r $TRAIN_BUCK/* g2net-float32-train\n",
    "!gsutil -m cp -r $TEST_BUCK/* g2net-float32-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-Umm9pCPllE"
   },
   "source": [
    "## 3. Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bx0QYH7PiDhj"
   },
   "source": [
    "### 3.1 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lnZ7sACi4FU"
   },
   "source": [
    "At this point, it only remains to prepare the datasets with the classes defined above before proceding with training. Of note is that a small proportion of the training dataset is stripped and used for validation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A0bz_4UVRtOG"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/g2net-float32-train/training_labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m sub_file \u001B[38;5;241m=\u001B[39m OV_PATH\u001B[38;5;241m.\u001B[39mjoinpath(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mg2net-float32-test\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msample_submission.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m train_labels_file \u001B[38;5;241m=\u001B[39m OV_PATH\u001B[38;5;241m.\u001B[39mjoinpath(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mg2net-float32-train\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining_labels.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m train_df_ori \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_labels_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m test_df_ori \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(sub_file)\n\u001B[1;32m      8\u001B[0m train_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame([Path(x)\u001B[38;5;241m.\u001B[39mstem \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mglob(TRAIN_PATH \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/*.tfrec\u001B[39m\u001B[38;5;124m\"\u001B[39m)], columns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[0;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    947\u001B[0m )\n\u001B[1;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    602\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    604\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 605\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1734\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1737\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1738\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1739\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1740\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1741\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1742\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1743\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1744\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/envs/tf-g2net/lib/python3.8/site-packages/pandas/io/common.py:856\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    851\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    852\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    854\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    855\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 856\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    864\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    865\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/content/g2net-float32-train/training_labels.csv'"
     ]
    }
   ],
   "source": [
    "# Prepare original dataframes \n",
    "sub_file = OV_PATH.joinpath(\"g2net-float32-test\", \"sample_submission.csv\")\n",
    "train_labels_file = OV_PATH.joinpath(\"g2net-float32-train\", \"training_labels.csv\")\n",
    "\n",
    "train_df_ori = pd.read_csv(train_labels_file)\n",
    "test_df_ori = pd.read_csv(sub_file)\n",
    "\n",
    "train_df = pd.DataFrame([Path(x).stem for x in tf.io.gfile.glob(TRAIN_PATH + \"/*.tfrec\")], columns = [\"id\"])\n",
    "train_df = train_df.sample(frac = 1, random_state = Config.SEED_SPLIT).reset_index(drop = True)\n",
    "test_df = pd.DataFrame([Path(x).stem for x in tf.io.gfile.glob(TEST_PATH + \"/*.tfrec\")], columns = [\"id\"])\n",
    "\n",
    "n_split = np.int32(train_df.shape[0] * Config.SPLIT)\n",
    "training_df = train_df.loc[:n_split - 1, :]\n",
    "validation_df = train_df.loc[n_split:, :]\n",
    "        \n",
    "training_gen = DatasetGeneratorTF(training_df, TRAIN_PATH, batch_size = Config.BATCH_SIZE, dtype = dtype)\n",
    "validation_gen = DatasetGeneratorTF(validation_df, TRAIN_PATH, batch_size = Config.BATCH_SIZE, dtype = dtype)\n",
    "test_gen = DatasetGeneratorTF(test_df, TEST_PATH, batch_size = Config.BATCH_SIZE_TEST, dtype = dtype)\n",
    "    \n",
    "training_ds = training_gen.get_dataset(buffer_size = 2048)\n",
    "validation_ds = validation_gen.get_dataset(buffer_size = 2048)\n",
    "test_ds = test_gen.get_dataset(shuffle = False, repeat = False, target = False)\n",
    "\n",
    "# Estimate number of steps per train, validation and test sets\n",
    "ns_training = np.int32(train_df_ori.shape[0] * Config.SPLIT)\n",
    "ns_validation = train_df_ori.shape[0] - ns_training\n",
    "ns_test = test_df_ori.shape[0]\n",
    "spe_training = np.int32(np.ceil(ns_training / Config.BATCH_SIZE))\n",
    "spe_validation = np.int32(np.ceil(ns_validation / Config.BATCH_SIZE))\n",
    "spe_test = np.int32(np.ceil(ns_test / Config.BATCH_SIZE_TEST))\n",
    "\n",
    "test_ds_id = test_ds.map(lambda data, identity: tf.strings.unicode_encode(\n",
    "    identity, \"UTF-8\"))\n",
    "test_ds_id = test_ds_id.unbatch()\n",
    "test_ids = next(iter(test_ds_id.batch(test_df_ori.shape[0]))).numpy().astype(\"U\")\n",
    "test_ds = test_ds.map(lambda data, identity: data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_wXjaNHjNJe"
   },
   "source": [
    "The building blocks of the model are already implemented in the cloned G2Net source code. The same applies to the model, which, in this case, is compiled outside the scope of the method that builds it. Now we are ready to build the model, preload model weights from local storage (weights other than those provided by AutoML) and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2l7TcMlhRtOH",
    "outputId": "b9ceb36e-a7e5-4bd2-c5c7-ec6b45bd1ab3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strategy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Create model, compile and display summary within the scope of the \u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# distribution strategy\u001B[39;00m\n\u001B[1;32m      3\u001B[0m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39mclear_session()\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mstrategy\u001B[49m\u001B[38;5;241m.\u001B[39mscope():\n\u001B[1;32m      5\u001B[0m         model_gen \u001B[38;5;241m=\u001B[39m G2NetEfficientNet(input_shape \u001B[38;5;241m=\u001B[39m \n\u001B[1;32m      6\u001B[0m                                       (Config\u001B[38;5;241m.\u001B[39mN_SAMPLES, Config\u001B[38;5;241m.\u001B[39mN_DETECT),\n\u001B[1;32m      7\u001B[0m                                       window_shape \u001B[38;5;241m=\u001B[39m Config\u001B[38;5;241m.\u001B[39mTUKEY_SHAPE,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     24\u001B[0m                                       w_mask_f \u001B[38;5;241m=\u001B[39m Config\u001B[38;5;241m.\u001B[39mW_MASK,\n\u001B[1;32m     25\u001B[0m                                       strategy \u001B[38;5;241m=\u001B[39m device)\n\u001B[1;32m     26\u001B[0m         model \u001B[38;5;241m=\u001B[39m model_gen\u001B[38;5;241m.\u001B[39mget_model(effnet_id \u001B[38;5;241m=\u001B[39m Config\u001B[38;5;241m.\u001B[39mMODEL_ID, \n\u001B[1;32m     27\u001B[0m                                     weights \u001B[38;5;241m=\u001B[39m Config\u001B[38;5;241m.\u001B[39mMODEL_ID_WEIGHTS)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'strategy' is not defined"
     ]
    }
   ],
   "source": [
    "# Create model, compile and display summary within the scope of the \n",
    "# distribution strategy\n",
    "tf.keras.backend.clear_session()\n",
    "with strategy.scope():\n",
    "        model_gen = G2NetEfficientNet(input_shape = \n",
    "                                      (Config.N_SAMPLES, Config.N_DETECT),\n",
    "                                      window_shape = Config.TUKEY_SHAPE,\n",
    "                                      trainable_window = Config.TRAINABLE_TUKEY,\n",
    "                                      sample_rate = Config.SAMPLE_RATE,\n",
    "                                      degree_filt = Config.DEGREE_FILT,\n",
    "                                      f_band_filt = Config.F_BAND_FILT,\n",
    "                                      trainable_filt = Config.TRAINABLE_FILT,\n",
    "                                      hop_length = Config.HOP_LENGTH,\n",
    "                                      f_band_spec = Config.F_BAND_SPEC,\n",
    "                                      bins_per_octave = Config.BINS_PER_OCTAVE,\n",
    "                                      window_cqt = Config.WINDOW_CQT,\n",
    "                                      resize_shape = \n",
    "                                      (Config.IMAGE_SIZE, Config.IMAGE_SIZE),\n",
    "                                      p_perm = Config.P_PERM,\n",
    "                                      p_mask = Config.P_MASK, \n",
    "                                      n_max_mask_t = Config.N_MAX_MASK,\n",
    "                                      w_mask_t = Config.W_MASK,\n",
    "                                      n_max_mask_f = Config.N_MAX_MASK,\n",
    "                                      w_mask_f = Config.W_MASK,\n",
    "                                      strategy = device)\n",
    "        model = model_gen.get_model(effnet_id = Config.MODEL_ID, \n",
    "                                    weights = Config.MODEL_ID_WEIGHTS)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = Config.LEARNING_RATE)\n",
    "        # optimizer = AdaBeliefOptimizer(learning_rate = Config.LEARNING_RATE, \n",
    "        #                                amsgrad = False, print_change_log = False)\n",
    "        model.compile(optimizer = optimizer, \n",
    "                  loss = \"binary_crossentropy\",\n",
    "                  metrics = [tf.keras.metrics.AUC()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNODhIFSuUdg"
   },
   "outputs": [],
   "source": [
    "if Config.MODEL_PRELOAD:\n",
    "    pretrained_model = Config.MODEL_PATH.joinpath(Config.MODEL_PRELOAD_NAME)\n",
    "    local = tf.train.CheckpointOptions(experimental_io_device = \"/job:localhost\")\n",
    "    if tf.io.gfile.isdir(pretrained_model):\n",
    "        pretrained_model = tf.train.latest_checkpoint(pretrained_model)\n",
    "    model.load_weights(pretrained_model, options = local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5uqxf-CRtOI",
    "outputId": "c8e7e06b-66cf-40e5-ee28-bfca74d4dcf8"
   },
   "outputs": [],
   "source": [
    "# Train model with training and validation sets with checkpoints and control \n",
    "# over training validation loss plateaus\n",
    "if Config.MODEL_TRAIN:\n",
    "    lr_callback = tf.keras.callbacks.ReduceLROnPlateau(patience = 1, monitor = \"val_loss\", cooldown = 0, verbose = 1)\n",
    "    \n",
    "    local = tf.train.CheckpointOptions(experimental_io_device='/job:localhost')\n",
    "    check_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath = Config.CKPT_PATH.joinpath(\"ckpt-{epoch:d}\"),\n",
    "            save_weights_only = True,\n",
    "            monitor = \"val_auc\",\n",
    "            mode = \"max\",\n",
    "            save_best_only = False,\n",
    "            options = local)\n",
    "    \n",
    "    train_history = model.fit(training_ds, epochs = Config.EPOCHS, batch_size = Config.BATCH_SIZE, \n",
    "                              validation_data = validation_ds, steps_per_epoch = spe_training,\n",
    "                              validation_steps = spe_validation, callbacks = [lr_callback, check_callback])\n",
    "\n",
    "    #best_model_path = tf.train.latest_checkpoint(Config.CKPT_PATH)\n",
    "    #model.load_weights(best_model_path, options = local)\n",
    "\n",
    "    Config.MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "    model.save_weights(Config.MODEL_PATH.joinpath(Config.MODEL_SAVE_NAME), options = local)\n",
    "\n",
    "    train_hist_df = pd.DataFrame(train_history.history)\n",
    "    train_hist_df.to_csv(Config.HISTORY_NAME, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQGL2yztxsys"
   },
   "source": [
    "### 3.2 Predicting with the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "288sVKRlx8GV"
   },
   "source": [
    "Once you are happy with the model, it is time to make predictions on the test set and explore a bit what is actually doing. First, try to obtain the predictions for the full test dataset and plot the output distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "ckvqjsTlRtOI",
    "outputId": "eaf82abd-141c-4b98-a2ae-bc057ce8e8b5"
   },
   "outputs": [],
   "source": [
    "# Predict on test set and save to submission file\n",
    "if Config.MODEL_PREDICT:\n",
    "    preds_test = model.predict(test_ds, batch_size = Config.BATCH_SIZE_TEST, \n",
    "                               steps = spe_test, verbose = 1)\n",
    "\n",
    "    sub_df = pd.DataFrame({\n",
    "        \"id\": test_ids,\n",
    "        \"target\": preds_test.flatten()\n",
    "    })\n",
    "\n",
    "    sub_df = sub_df.sort_values(\"id\").reset_index(drop = True)\n",
    "        \n",
    "    sub_df.to_csv(Config.PREDICTIONS_NAME, index = False)\n",
    "\n",
    "    plt.style.use(\"seaborn\")\n",
    "    print()\n",
    "    print(\"Test dataset output distribution\")\n",
    "    sns.displot(sub_df, x = \"target\", kind = \"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azXTbT9QzdYI"
   },
   "source": [
    "Now let's try to break down the model into its constituent parts and plot the intermediate data for a single example. You might see that, depending on the example, visually identifying a merger chirp becomes difficult or even impossible mainly due other low and high frequency sources of noise (in this case simulated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v4z4mOmzd5M"
   },
   "outputs": [],
   "source": [
    "if Config.PLOT_EXAMPLE:\n",
    "\n",
    "    permute = model.get_layer(\"permute\")\n",
    "    window = model.get_layer(\"window\")\n",
    "    bandpass = model.get_layer(\"bandpass\")\n",
    "    cqt = model.get_layer(\"cqt\")\n",
    "    resize = model.get_layer(\"resize\")\n",
    "    permute = model.get_layer(\"permute\")\n",
    "    mask = model.get_layer(\"mask\")\n",
    "    effnet = model.get_layer(Config.MODEL_ID)\n",
    "    flatten = model.get_layer(\"flatten\")\n",
    "    dense = model.get_layer(\"dense\")\n",
    "        \n",
    "    if Config.PLOT_TEST:\n",
    "        for data, _ in test_ds.take(1):\n",
    "            x_ref = data.numpy()[0, ...][np.newaxis, ...]\n",
    "    else:\n",
    "        for data, _ in training_ds.take(1):\n",
    "            x_ref = data.numpy()[0, ...][np.newaxis, ...]\n",
    "\n",
    "    x = np.squeeze(x_ref)\n",
    "    y = x_ref\n",
    "        \n",
    "    y = window(y)\n",
    "    y_win = np.squeeze(y.numpy())\n",
    "    y = bandpass(y)\n",
    "    y_band = np.squeeze(y.numpy())\n",
    "    y = cqt(y, training = False)\n",
    "    y = resize(y)\n",
    "    y_spec = np.squeeze(y.numpy())\n",
    "    y = permute(y, training = True)\n",
    "    y = mask(y, training = True)\n",
    "    y_masked = np.squeeze(y.numpy())\n",
    "    y = effnet(y)\n",
    "    y = flatten(y)\n",
    "    y = dense(y)\n",
    "    y_dense = np.squeeze(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "hThBqe32wYDM",
    "outputId": "0ffa2bee-a155-4354-ea8c-6e37443fc3df"
   },
   "outputs": [],
   "source": [
    "if Config.PLOT_EXAMPLE:\n",
    "    print(\"Standardised signals\")\n",
    "    PlottingUtilities.plot_wave(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "Q7Hk5NAIwnnL",
    "outputId": "1feda59a-7e46-43ee-ad22-1942d8c66b0b"
   },
   "outputs": [],
   "source": [
    "if Config.PLOT_EXAMPLE:\n",
    "    print(\"Tappered signals\")\n",
    "    PlottingUtilities.plot_wave(y_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "NYzTBF8Twrfb",
    "outputId": "e646590a-84e7-434a-916b-8473338fe6dc"
   },
   "outputs": [],
   "source": [
    "if Config.PLOT_EXAMPLE:\n",
    "    print(\"Filtered signals\")\n",
    "    PlottingUtilities.plot_wave(y_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "T8zptaWqwuNa",
    "outputId": "7513457b-5888-4a85-fb84-bad47152cee0"
   },
   "outputs": [],
   "source": [
    "if Config.PLOT_EXAMPLE:\n",
    "    print(\"CQT spectrogram\")\n",
    "    PlottingUtilities.plot_spectrogram(y_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "xHDuWwIawwsW",
    "outputId": "678ec0fe-cd93-491f-f6d3-a6a2e118c7fc"
   },
   "outputs": [],
   "source": [
    "if Config.PLOT_EXAMPLE:\n",
    "    print(\"Masked CQT spectrogram\")\n",
    "    PlottingUtilities.plot_spectrogram(y_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvjyxodczQSz"
   },
   "source": [
    "Don't forget to save the results to your Google Drive! Make sure you have enough space as some models are truly heavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuBWafX16UUy",
    "outputId": "97b43bec-2065-473d-b95d-00a5048acc36"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\", force_remount = True)\n",
    "os.environ[\"OUT_NAME\"] = \"g2net_output\"\n",
    "!echo $OUT_NAME\n",
    "!mkdir -p $OUT_NAME\n",
    "!cp -r checkpoints $OUT_NAME\n",
    "!cp -r models $OUT_NAME\n",
    "!cp -r *.csv $OUT_NAME\n",
    "!cp -r $OUT_NAME /content/gdrive/MyDrive/\n",
    "drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzTLh7qt9YwI"
   },
   "source": [
    "\n",
    "The best G2Net single model was obtained with trainable Tukey window and bandpass layers, a non-trainable CQT, a resize size of 384, an EfficientNet v2 S backbone and training in a Tesla V100 (16GB) GPU with a batch size of 32 (learning rates in the range 0.0003 to 0.00001. The score was boosted with an averaging ensemble of several models with different settings. \n",
    "\n",
    "The ROC & Roll team encourages you to play with the code, propose improvements and even introduce new layers that might be of use!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "g2net_gpu_colab_short.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "tf-g2net",
   "language": "python",
   "display_name": "tf-g2net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
